{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285581f6",
   "metadata": {},
   "source": [
    "#  DT Regressor - One Block Code with Pipline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f3a6cfe",
   "metadata": {},
   "source": [
    "This NB uses;\n",
    "1) Pipline for handling null values both categorical and numeric columns + encoding + analysis. So, if you want to deploy it on Streamlit, you will not need to call encoder. Just calling model is enough. \n",
    "2) Target variable is \"Default\", meaning taht customer will not pay credit. 0--->No Default Risk, 1---> Default\n",
    "3) We don't need apply scaling in tree base models.\n",
    "4) We should use ordinal encoding on categorical variables in features. But this data set not including any categorical data as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88ff3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL METRICS FOR BASE MODEL\n",
      "Evaluation metrics for Train data:\n",
      "Mean Squared Error: 0.004380208333333334\n",
      "R2 Score: 0.9998343155835676\n",
      "\n",
      "\n",
      "Evaluation metrics for Test data:\n",
      "Mean Squared Error: 2.0806729508196726\n",
      "R2 Score: 0.9096757041703469\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'regressor__max_depth': 10, 'regressor__max_features': None, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2}\n",
      "\n",
      "----EVAL METRICS FOR BEST MODEL----\n",
      "\n",
      "Evaluation metrics for Train (Best Model) data:\n",
      "Mean Squared Error: 0.032808939133986935\n",
      "R2 Score: 0.9987574370886227\n",
      "\n",
      "\n",
      "Evaluation metrics for Test (Best Model) data:\n",
      "Mean Squared Error: 2.093356527607604\n",
      "R2 Score: 0.8882106122943842\n",
      "\n",
      "\n",
      "               Metric  BaseModlTrain  BaseModlTest  BestModTrain  BestModlTest\n",
      "0  Mean Squared Error       0.004380      2.080673      0.032809      2.093357\n",
      "1            R2 Score       0.999834      0.909676      0.998759      0.909125\n",
      " \n",
      "Final model saved as 'final_DT_regression_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "import warnings # for ignoring unnecessary warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "# ------------------------ #\n",
    "\n",
    "# 1) Load the dataset \n",
    "df = pd.read_excel('sample_data.xlsx') \n",
    "# Assume the target variable in the Excel file is named \"Target\"\n",
    "# Other variable names are not important here.\n",
    "\n",
    "# 2) Separate features and target variable from the dataset\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 3) Create transformers for data preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)) ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# 4) Create a pipeline with a Decision Tree Regressor\n",
    "base_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# 5) Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6) Train and evaluate the Base Model\n",
    "base_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7) Predictions and evaluation metrics\n",
    "print(\"EVAL METRICS FOR BASE MODEL\")\n",
    "y_train_pred = base_pipeline.predict(X_train)\n",
    "y_test_pred = base_pipeline.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, data_type=\"Train\"):\n",
    "    print(f\"Evaluation metrics for {data_type} data:\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_true, y_pred)}\")\n",
    "    print(f\"R2 Score: {r2_score(y_true, y_pred)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "evaluate_model(y_train, y_train_pred, \"Train\")\n",
    "evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# 8) Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(base_pipeline, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 9) Build and evaluate the Best Model\n",
    "print(\"\")\n",
    "print(\"----EVAL METRICS FOR BEST MODEL----\")\n",
    "print(\"\")\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "y_train_best_pred = best_pipeline.predict(X_train)\n",
    "y_test_best_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "evaluate_model(y_train_best_pred, y_train, \"Train (Best Model)\")\n",
    "evaluate_model(y_test_best_pred, y_test, \"Test (Best Model)\")\n",
    "\n",
    "# Compare metrics\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Metric': ['Mean Squared Error', 'R2 Score'],\n",
    "    'BaseModlTrain': [mean_squared_error(y_train, y_train_pred), r2_score(y_train, y_train_pred)],\n",
    "    'BaseModlTest': [mean_squared_error(y_test, y_test_pred), r2_score(y_test, y_test_pred)],\n",
    "    'BestModTrain': [mean_squared_error(y_train, y_train_best_pred), r2_score(y_train, y_train_best_pred)],\n",
    "    'BestModlTest': [mean_squared_error(y_test, y_test_best_pred), r2_score(y_test, y_test_best_pred)]\n",
    "})\n",
    "\n",
    "print(metrics_comparison)\n",
    "\n",
    "# 10) Train the Final Model on the entire dataset\n",
    "final_model = best_pipeline.fit(X, y)\n",
    "\n",
    "# 11) Save the Final Model\n",
    "joblib.dump(final_model, 'final_DT_regression_model.pkl')\n",
    "\n",
    "print(\" \")\n",
    "print(\"Final model saved as 'final_DT_regression_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9610cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL METRICS FOR BASE MODEL\n",
      "Evaluation metrics for Train data:\n",
      "Mean Squared Error: 19.409700533333332\n",
      "R2 Score: 0.26581462312646265\n",
      "\n",
      "\n",
      "Evaluation metrics for Test data:\n",
      "Mean Squared Error: 23.55598183606557\n",
      "R2 Score: -0.022591018487807313\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'regressor__metric': 'manhattan', 'regressor__n_neighbors': 9, 'regressor__weights': 'distance'}\n",
      "\n",
      "----EVAL METRICS FOR BEST MODEL----\n",
      "\n",
      "Evaluation metrics for Train (Best Model) data:\n",
      "Mean Squared Error: 0.004380208333333334\n",
      "R2 Score: 0.9998342881276927\n",
      "\n",
      "\n",
      "Evaluation metrics for Test (Best Model) data:\n",
      "Mean Squared Error: 25.454692442613613\n",
      "R2 Score: -1.5479686471776968\n",
      "\n",
      "\n",
      "               Metric  BaseModlTrain  BaseModlTest  BestModTrain  BestModlTest\n",
      "0  Mean Squared Error      19.409701     23.555982      0.004380     25.454692\n",
      "1            R2 Score       0.265815     -0.022591      0.999834     -0.105016\n",
      " \n",
      "Final model saved as 'final_knn_regression_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "import warnings  # for ignoring unnecessary warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "# ------------------------ #\n",
    "\n",
    "# 1) Load the dataset \n",
    "df = pd.read_excel('sample_data.xlsx') \n",
    "# Assume the target variable in the Excel file is named \"Target\"\n",
    "# Other variable names are not important here.\n",
    "\n",
    "# 2) Separate features and target variable from the dataset\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 3) Create transformers for data preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# 4) Create a pipeline with a KNeighbors Regressor\n",
    "base_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# 5) Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6) Train and evaluate the Base Model\n",
    "base_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7) Predictions and evaluation metrics\n",
    "print(\"EVAL METRICS FOR BASE MODEL\")\n",
    "y_train_pred = base_pipeline.predict(X_train)\n",
    "y_test_pred = base_pipeline.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, data_type=\"Train\"):\n",
    "    print(f\"Evaluation metrics for {data_type} data:\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_true, y_pred)}\")\n",
    "    print(f\"R2 Score: {r2_score(y_true, y_pred)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "evaluate_model(y_train, y_train_pred, \"Train\")\n",
    "evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# 8) Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'regressor__n_neighbors': [3, 5, 7, 9],\n",
    "    'regressor__weights': ['uniform', 'distance'],\n",
    "    'regressor__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(base_pipeline, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 9) Build and evaluate the Best Model\n",
    "print(\"\")\n",
    "print(\"----EVAL METRICS FOR BEST MODEL----\")\n",
    "print(\"\")\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "y_train_best_pred = best_pipeline.predict(X_train)\n",
    "y_test_best_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "evaluate_model(y_train_best_pred, y_train, \"Train (Best Model)\")\n",
    "evaluate_model(y_test_best_pred, y_test, \"Test (Best Model)\")\n",
    "\n",
    "# Compare metrics\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Metric': ['Mean Squared Error', 'R2 Score'],\n",
    "    'BaseModlTrain': [mean_squared_error(y_train, y_train_pred), r2_score(y_train, y_train_pred)],\n",
    "    'BaseModlTest': [mean_squared_error(y_test, y_test_pred), r2_score(y_test, y_test_pred)],\n",
    "    'BestModTrain': [mean_squared_error(y_train, y_train_best_pred), r2_score(y_train, y_train_best_pred)],\n",
    "    'BestModlTest': [mean_squared_error(y_test, y_test_best_pred), r2_score(y_test, y_test_best_pred)]\n",
    "})\n",
    "\n",
    "print(metrics_comparison)\n",
    "\n",
    "# 10) Train the Final Model on the entire dataset\n",
    "final_model = best_pipeline.fit(X, y)\n",
    "\n",
    "# 11) Save the Final Model\n",
    "joblib.dump(final_model, 'final_knn_regression_model.pkl')\n",
    "\n",
    "print(\" \")\n",
    "print(\"Final model saved as 'final_knn_regression_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f09f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
