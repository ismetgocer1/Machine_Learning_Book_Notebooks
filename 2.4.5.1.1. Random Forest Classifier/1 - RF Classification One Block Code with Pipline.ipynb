{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4ea99e",
   "metadata": {},
   "source": [
    "# RF Classification One Block Code with Pipline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9efeca8c",
   "metadata": {},
   "source": [
    "This NB uses;\n",
    "0) Pipline for handling null values both categorical and numeric columns + encoding + analysis. So, if you want to deploy i on Streamlit, you will not need to call encoder. Just calling model is enough. \n",
    "1) \"class_weight=\"balanced\" \" and\n",
    "2) \"stratfy = y\" for handling unbalance at the target variable.\n",
    "3) Target variable is \"Default\", meaning taht customer will not pay credit. 0--->No Default Risk, 1---> Default\n",
    "4) We don't need apply scaling in tree base models.\n",
    "5) We don't need apply encoding on Target variable in tree base models.\n",
    "6) We should use ordinal encoding on categorical variables in features. But this data set not including any categorical data as feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f56f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL METRICS FOR BASE MODEL\n",
      "Evaluation metrics for Train data:\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       359\n",
      "           1       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00       400\n",
      "   macro avg       1.00      1.00      1.00       400\n",
      "weighted avg       1.00      1.00      1.00       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[359   0]\n",
      " [  0  41]]\n",
      "\n",
      "\n",
      "Evaluation metrics for Test data:\n",
      "Accuracy: 0.89\n",
      "F1 Score: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        90\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.45      0.49      0.47       100\n",
      "weighted avg       0.81      0.89      0.85       100\n",
      "\n",
      "Confusion Matrix:\n",
      "[[89  1]\n",
      " [10  0]]\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'classifier__max_depth': None, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50}\n",
      "\n",
      "----EVAL METRICS FOR BEST MODEL----\n",
      "\n",
      "Evaluation metrics for Train (Best Model) data:\n",
      "Accuracy: 0.9975\n",
      "F1 Score: 0.9876543209876543\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       360\n",
      "           1       0.98      1.00      0.99        40\n",
      "\n",
      "    accuracy                           1.00       400\n",
      "   macro avg       0.99      1.00      0.99       400\n",
      "weighted avg       1.00      1.00      1.00       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[359   1]\n",
      " [  0  40]]\n",
      "\n",
      "\n",
      "Evaluation metrics for Test (Best Model) data:\n",
      "Accuracy: 0.9\n",
      "F1 Score: 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       100\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.50      0.45      0.47       100\n",
      "weighted avg       1.00      0.90      0.95       100\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90 10]\n",
      " [ 0  0]]\n",
      "\n",
      "\n",
      "     Metric  BaseModelTrain  BaseModelTest  BestModelTrain  BestModelTest\n",
      "0  Accuracy             1.0           0.89        0.997500            0.9\n",
      "1  F1 Score             1.0           0.00        0.987654            0.0\n",
      " \n",
      "Final model saved as 'final_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "import joblib\n",
    "\n",
    "import warnings # for ignoring unnecessary warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "# ------------------------ #\n",
    "\n",
    "# 1) Load the dataset \n",
    "df = pd.read_excel('sample_dataset.xlsx') \n",
    "# !If you name the target variable in the Excel file \"Target\", you will not have any problems with the codes below.\n",
    "# Other variable's names are not important here.\n",
    "\n",
    "# 2) Separate features and target variable from the dataset\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 3) Create transformers for data preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)) ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# 4) Create a pipeline with a RandomForest Classifier\n",
    "base_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "# 5) Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 6) Train and evaluate the Base Model\n",
    "base_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 7) Predictions and evaluation metrics\n",
    "print(\"EVAL METRICS FOR BASE MODEL\")\n",
    "y_train_pred = base_pipeline.predict(X_train)\n",
    "y_test_pred = base_pipeline.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, data_type=\"Train\"):\n",
    "    print(f\"Evaluation metrics for {data_type} data:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "evaluate_model(y_train, y_train_pred, \"Train\")\n",
    "evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# 8) Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(base_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 9) Build and evaluate the Best Model\n",
    "print(\"\")\n",
    "print(\"----EVAL METRICS FOR BEST MODEL----\")\n",
    "print(\"\")\n",
    "\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "y_train_best_pred = best_pipeline.predict(X_train)\n",
    "y_test_best_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "evaluate_model(y_train_best_pred, y_train, \"Train (Best Model)\")\n",
    "evaluate_model(y_test_best_pred, y_test, \"Test (Best Model)\")\n",
    "\n",
    "# Compare metrics\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'F1 Score'],\n",
    "    'BaseModelTrain': [accuracy_score(y_train, y_train_pred), f1_score(y_train, y_train_pred)],\n",
    "    'BaseModelTest': [accuracy_score(y_test, y_test_pred), f1_score(y_test, y_test_pred)],\n",
    "    'BestModelTrain': [accuracy_score(y_train, y_train_best_pred), f1_score(y_train, y_train_best_pred)],\n",
    "    'BestModelTest': [accuracy_score(y_test, y_test_best_pred), f1_score(y_test, y_test_best_pred)]\n",
    "})\n",
    "\n",
    "print(metrics_comparison)\n",
    "\n",
    "# 10) Train the Final Model on the entire dataset\n",
    "final_model = best_pipeline.fit(X, y)\n",
    "\n",
    "# 11) Save the Final Model\n",
    "joblib.dump(final_model, 'final_model.pkl')\n",
    "\n",
    "print(\" \")\n",
    "print(\"Final model saved as 'final_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e0e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
